{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09382688-ecb8-4d8e-8208-1a776d9f4f39",
   "metadata": {},
   "source": [
    "1. Importing json file which contains intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0d2e9dc-4edf-41e7-b5bb-76a00c9c6c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'greeting',\n",
       "   'patterns': ['Hi',\n",
       "    'Hello',\n",
       "    'Hey',\n",
       "    'Good morning',\n",
       "    'Good afternoon',\n",
       "    'Hi there',\n",
       "    'Hey there',\n",
       "    'Yo'],\n",
       "   'responses': [\"Hey! How's it going?\",\n",
       "    \"Hello! What's up?\",\n",
       "    'Hi there! How can I help?',\n",
       "    \"Hi! How's your day?\",\n",
       "    \"Hello! What's new?\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'noanswer',\n",
       "   'patterns': [],\n",
       "   'responses': [\"Sorry, can't understand you\",\n",
       "    'Please give me more info',\n",
       "    'Not sure I understand'],\n",
       "   'context': ''},\n",
       "  {'tag': 'job',\n",
       "   'patterns': ['What is your job', 'What is your work'],\n",
       "   'responses': ['My job is to make you feel like everything is okay.',\n",
       "    'I work to serve you as well as possible'],\n",
       "   'context': ''},\n",
       "  {'tag': 'age',\n",
       "   'patterns': ['What is your age', 'How old are you', 'When were you born'],\n",
       "   'responses': ['I was born in 2021'],\n",
       "   'context': ''},\n",
       "  {'tag': 'feeling',\n",
       "   'patterns': ['How are you today', 'How are you'],\n",
       "   'responses': ['I am feeling good, you?',\n",
       "    'Very good and you?',\n",
       "    \"Actually, I'm okay and you?\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'good',\n",
       "   'patterns': ['I am good too',\n",
       "    'I feel fine',\n",
       "    'Good !',\n",
       "    'Fine',\n",
       "    'I am good',\n",
       "    'I am great',\n",
       "    'great'],\n",
       "   'responses': ['That is perfect!', \"So, everything's okay!\"],\n",
       "   'context': 'feeling'},\n",
       "  {'tag': 'bad',\n",
       "   'patterns': ['I am feeling bad', 'No I am sad', 'No'],\n",
       "   'responses': ['I hope you will feel better !'],\n",
       "   'context': 'feeling'},\n",
       "  {'tag': 'actions',\n",
       "   'patterns': ['What can you do', 'What can I ask you', 'Can you help me'],\n",
       "   'responses': ['I can do a lot of things but here are some of my skills, you can ask me: the capital of a country, its currency and its area. A random number. To calculate a math operation.'],\n",
       "   'context': ''},\n",
       "  {'tag': 'women',\n",
       "   'patterns': ['Are you a girl', 'You are a women'],\n",
       "   'responses': ['Sure, I am a women'],\n",
       "   'context': ''},\n",
       "  {'tag': 'men',\n",
       "   'patterns': ['Are you a men', 'Are you a boy'],\n",
       "   'responses': ['No, I am a women'],\n",
       "   'context': ''},\n",
       "  {'tag': 'thanks',\n",
       "   'patterns': ['Thank you',\n",
       "    'Thank you very much',\n",
       "    'thanks',\n",
       "    'Thank you',\n",
       "    'Thanks a lot',\n",
       "    'Thanks',\n",
       "    'Much appreciated',\n",
       "    \"You're the best\"],\n",
       "   'responses': ['I only do my job️',\n",
       "    'No problem!',\n",
       "    'No worries!',\n",
       "    'Happy to help!',\n",
       "    'Anytime!',\n",
       "    \"You're welcome!\",\n",
       "    'Glad I could help!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'goodbye',\n",
       "   'patterns': ['Goodbye',\n",
       "    'Good afternoon',\n",
       "    'Bye',\n",
       "    'Goodbye',\n",
       "    'Bye',\n",
       "    'See you later',\n",
       "    'Take care',\n",
       "    'Catch you later',\n",
       "    'Peace out'],\n",
       "   'responses': ['Goodbye!',\n",
       "    'See you soon!',\n",
       "    'Bye! Have an awesome day!',\n",
       "    'See you later, alligator!',\n",
       "    'Take care! Talk soon.',\n",
       "    'Catch you later!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'city',\n",
       "   'patterns': ['Where do you live'],\n",
       "   'responses': ['I live in a server located in the US!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'action',\n",
       "   'patterns': ['What are you doing'],\n",
       "   'responses': [\"Actually, I'm chatting with somebody\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'wait',\n",
       "   'patterns': ['Can you wait 2 minutes', 'Please wait', 'Wait 2 secs please'],\n",
       "   'responses': ['Sure! I wait.'],\n",
       "   'context': ''},\n",
       "  {'tag': 'still_there',\n",
       "   'patterns': ['Are you still there?', 'Are you here?'],\n",
       "   'responses': ['Of course! Always at your service.'],\n",
       "   'context': ''},\n",
       "  {'tag': 'personal_info',\n",
       "   'patterns': ['How old are you?',\n",
       "    \"What's your age?\",\n",
       "    'When were you created?',\n",
       "    \"What's your name?\",\n",
       "    'Do you have a name?',\n",
       "    'Who are you?'],\n",
       "   'responses': [\"I'm ChatBot, your friendly virtual assistant!\",\n",
       "    \"I don't have an age, but I'm here to help you!\",\n",
       "    'You can call me ChatBot!',\n",
       "    \"I'm ChatBot, nice to meet you!\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'weather',\n",
       "   'patterns': [\"What's the weather like today?\",\n",
       "    'Tell me about the weather',\n",
       "    'Is it going to rain?',\n",
       "    \"How's the weather?\"],\n",
       "   'responses': [\"I can't check the weather, but you can try a weather app!\",\n",
       "    'Not sure, but you can check online!',\n",
       "    'Weather is always a surprise!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'help',\n",
       "   'patterns': ['Can you help me?',\n",
       "    'I need assistance',\n",
       "    'Help me with something',\n",
       "    'What can you do?',\n",
       "    'What are your features?',\n",
       "    'Tell me about your capabilities'],\n",
       "   'responses': [\"I'm here to chat and help with whatever you need!\",\n",
       "    'I can answer questions, tell jokes, and more. Just ask!',\n",
       "    \"What do you need help with? I'm here for you!\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'jokes',\n",
       "   'patterns': ['Tell me a joke',\n",
       "    'Can you make me laugh?',\n",
       "    'Share a funny story',\n",
       "    'Got any jokes?'],\n",
       "   'responses': [\"Why don't scientists trust atoms? Because they make up everything!\",\n",
       "    'Why did the scarecrow win an award? Because he was outstanding in his field!',\n",
       "    \"Want to hear a construction joke? Oh, never mind, I'm still working on it.\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'small_talk',\n",
       "   'patterns': ['How are you?',\n",
       "    \"How's it going?\",\n",
       "    \"What's up?\",\n",
       "    \"How's your day?\",\n",
       "    'How are things?',\n",
       "    \"How's life?\",\n",
       "    \"How's everything?\"],\n",
       "   'responses': [\"I'm doing great! How about you?\",\n",
       "    'All good here! What about you?',\n",
       "    \"Just chilling! How's your day going?\",\n",
       "    \"Life's good! How's everything with you?\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'compliment',\n",
       "   'patterns': [\"You're awesome\",\n",
       "    \"You're the best\",\n",
       "    'I like you',\n",
       "    \"You're cool\",\n",
       "    'Thanks for being awesome'],\n",
       "   'responses': [\"You're too kind!\",\n",
       "    \"Thanks! You're awesome too!\",\n",
       "    'I like you too!',\n",
       "    'You rock!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'movie_recommendation',\n",
       "   'patterns': ['Recommend a movie',\n",
       "    \"What's a good movie to watch?\",\n",
       "    'Any movie suggestions?',\n",
       "    'What should I watch?'],\n",
       "   'responses': ['Depends on what you like! Have you seen any good comedies lately?',\n",
       "    \"How about a classic? You can't go wrong with something like 'The Shawshank Redemption'!\",\n",
       "    \"In the mood for action? 'Mad Max: Fury Road' is a wild ride!\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'music_recommendation',\n",
       "   'patterns': ['Recommend some music',\n",
       "    \"What's a good song to listen to?\",\n",
       "    'Any music suggestions?',\n",
       "    'What should I listen to?'],\n",
       "   'responses': [\"What genre do you like? I'm a fan of all kinds!\",\n",
       "    'How about some chill vibes with lo-fi beats?',\n",
       "    'In the mood for something upbeat? Try some pop hits!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'book_recommendation',\n",
       "   'patterns': ['Recommend a book',\n",
       "    \"What's a good book to read?\",\n",
       "    'Any book suggestions?',\n",
       "    'What should I read?'],\n",
       "   'responses': [\"If you like thrillers, 'Gone Girl' is a great choice!\",\n",
       "    \"For some fantasy, you can't go wrong with 'Harry Potter'!\",\n",
       "    \"In the mood for non-fiction? 'Sapiens' is really interesting!\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'sports_news',\n",
       "   'patterns': ['Tell me about sports news',\n",
       "    \"What's happening in the sports world?\",\n",
       "    'Any sports updates?',\n",
       "    \"What's new in sports?\"],\n",
       "   'responses': [\"There's always something happening in sports! Check out the latest news online.\",\n",
       "    'You can get the latest updates on sports news websites.',\n",
       "    \"I'm not a sports expert, but I can help you find the news!\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'tech_news',\n",
       "   'patterns': [\"What's new in technology?\",\n",
       "    'Tell me about tech trends',\n",
       "    'Any tech updates?',\n",
       "    \"What's happening in tech?\"],\n",
       "   'responses': ['Tech is always evolving! Have you checked out the latest gadgets?',\n",
       "    'You can stay updated with tech blogs and news sites.',\n",
       "    'So many cool innovations happening! What are you interested in?'],\n",
       "   'context': ''},\n",
       "  {'tag': 'coding_help',\n",
       "   'patterns': ['Can you help me with coding?',\n",
       "    'I need coding assistance',\n",
       "    'Programming help',\n",
       "    'How do I code this?'],\n",
       "   'responses': ['Sure, I can help with coding! What language are you using?',\n",
       "    \"Need help with a specific coding problem? I'm here for you!\",\n",
       "    \"Let's tackle that coding challenge together!\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'hobbies',\n",
       "   'patterns': ['What do you like to do for fun?',\n",
       "    'Any hobbies?',\n",
       "    'What are your interests?',\n",
       "    'Do you have any hobbies?'],\n",
       "   'responses': ['I love chatting with you and learning new things!',\n",
       "    'My hobby is helping people out with their questions.',\n",
       "    'I enjoy making people smile with my jokes and stories!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'favorite_color',\n",
       "   'patterns': [\"What's your favorite color?\"],\n",
       "   'responses': ['I love all colors equally!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'like_pizza',\n",
       "   'patterns': ['Do you like pizza?'],\n",
       "   'responses': [\"Pizza is awesome! What's your favorite topping?\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'favorite_movie',\n",
       "   'patterns': ['Do you have a favorite movie?'],\n",
       "   'responses': [\"I don't watch movies, but I've heard 'Inception' is a mind-bender!\"],\n",
       "   'context': ''}]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data_file = open(\"intents3.json\", encoding=\"utf-8\").read()\n",
    "data = json.loads(data_file)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a736f019-6d35-404a-88c6-fcc690a090b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"intents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba70ef-5484-4b1b-b3ee-c47cc7422d6c",
   "metadata": {},
   "source": [
    "2. Creating pattern lemmatizer which tokanize and lemmatize words in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c7c4f71-a15e-4cd5-b714-551d7c715d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import numpy as np\n",
    "#nltk.download(\"punkt\")\n",
    "#nltk.download(\"wordnet\")\n",
    "\n",
    "def pattern_lemmatizer(text):\n",
    "    pat_lemmatizer = WordNetLemmatizer()\n",
    "    return [pat_lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text.lower())]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a4a226-0e7f-4bf1-95dc-ac13929e898a",
   "metadata": {},
   "source": [
    "3. Create a algorithm to store each word in our json file, tags for each pattern(sentence), input patterns and target outputs for train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8253fbd5-0daa-44e4-a064-d631fd3160b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_lists(data):\n",
    "    words = []\n",
    "    tag_classes = []\n",
    "    predictor_patterns  = []\n",
    "    target_tags = []\n",
    "    \n",
    "    for intent in data[\"intents\"]:\n",
    "        for pattern in intent[\"patterns\"]:\n",
    "            tokens = nltk.word_tokenize(pattern)\n",
    "            words.extend(tokens)\n",
    "            predictor_patterns.append(pattern)\n",
    "            target_tags.append(intent[\"tag\"])\n",
    "        if intent[\"tag\"] not in tag_classes:\n",
    "            tag_classes.append(intent[\"tag\"])\n",
    "    tag_classes = sorted(tag_classes)\n",
    "    return words, tag_classes, predictor_patterns, target_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6290d9bd-e0a1-420a-9262-6ef6e087cbd0",
   "metadata": {},
   "source": [
    "4. Creating algorithms to make a Vocab which lemmatize each words in word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ad4727a-112f-4023-b8b6-6e8c42acea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vocab_maker(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    vocab = [lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n",
    "    vocab = sorted(set(vocab))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6013358d-885c-413a-b3dd-b7115ae86552",
   "metadata": {},
   "source": [
    "5. Bag of words function encode each sentence to a binary code array according to a rule with respect to our vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4a20f35-f776-4b1e-b738-bb58083ddec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(pattern, vocab):\n",
    "    bow=[]\n",
    "    for word in vocab:\n",
    "        bow.append(1) if word in pattern else bow.append(0)\n",
    "    return np.array(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b7695-404a-4c61-b974-1894be7aeada",
   "metadata": {},
   "source": [
    "6. Creating a Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c97bc5e-f222-4594-a860-eb25aadd5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words, tag_classes, predictor_patterns, target_tags = initialize_lists(data)\n",
    "vocab = vocab_maker(words)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "training = []\n",
    "out = [0]*len(tag_classes)\n",
    "for idx, pattern in enumerate(predictor_patterns):\n",
    "    pattern_lemma = lemmatizer.lemmatize(pattern.lower()) #for word in nltk.word_tokenize(text.lower())\n",
    "    #pattern_lemma = pattern_lemmatizer(pattern)\n",
    "    bow = bag_of_words(pattern_lemma, vocab)\n",
    "    output = list(out)\n",
    "    output[tag_classes.index(target_tags[idx])] = 1\n",
    "    training.append([bow, output])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e992392-763c-49e3-9560-7d46c5fd0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_training = training\n",
    "random.shuffle(random_training)\n",
    "training_array = np.array(random_training, dtype=object)\n",
    "train_X = np.array(list(training_array[:,0]))\n",
    "train_Y = np.array(list(training_array[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b51ac81-0a9c-4d43-9a35-41b63de5b41a",
   "metadata": {},
   "source": [
    "7. Training the model. The model we are using is a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8be5714e-aee1-47cc-aa55-bc40bd9478f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_shape=(train_X.shape[1],), activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(train_Y.shape[1], activation=\"softmax\"))\n",
    "                   \n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate =0.01),\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f287d429-a03c-47c7-b27d-7724853fe3f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,664</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m17,664\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,000</span> (109.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,000\u001b[0m (109.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,000</span> (109.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,000\u001b[0m (109.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f9ed244-d601-4133-bbd3-5ad2e03c9ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0504 - loss: 3.5171\n",
      "Epoch 2/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0711 - loss: 3.3526 \n",
      "Epoch 3/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1724 - loss: 3.1557 \n",
      "Epoch 4/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1968 - loss: 3.0437 \n",
      "Epoch 5/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2387 - loss: 2.8295 \n",
      "Epoch 6/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3027 - loss: 2.6157 \n",
      "Epoch 7/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3385 - loss: 2.3194 \n",
      "Epoch 8/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3851 - loss: 2.1386 \n",
      "Epoch 9/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4506 - loss: 1.9742 \n",
      "Epoch 10/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4373 - loss: 1.7919 \n",
      "Epoch 11/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4994 - loss: 1.7003 \n",
      "Epoch 12/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5957 - loss: 1.4713 \n",
      "Epoch 13/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5889 - loss: 1.2516 \n",
      "Epoch 14/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6467 - loss: 1.0893  \n",
      "Epoch 15/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5920 - loss: 1.2047 \n",
      "Epoch 16/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6577 - loss: 1.1475 \n",
      "Epoch 17/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7145 - loss: 0.8802 \n",
      "Epoch 18/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6873 - loss: 1.0221 \n",
      "Epoch 19/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8006 - loss: 0.7249 \n",
      "Epoch 20/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6577 - loss: 0.9088 \n",
      "Epoch 21/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7502 - loss: 0.7253 \n",
      "Epoch 22/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7288 - loss: 0.7859 \n",
      "Epoch 23/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.6755 \n",
      "Epoch 24/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7689 - loss: 0.7386 \n",
      "Epoch 25/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7980 - loss: 0.7415 \n",
      "Epoch 26/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.6319 \n",
      "Epoch 27/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8271 - loss: 0.5205 \n",
      "Epoch 28/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7816 - loss: 0.6886 \n",
      "Epoch 29/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.6220 \n",
      "Epoch 30/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8310 - loss: 0.5383  \n",
      "Epoch 31/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8751 - loss: 0.4348 \n",
      "Epoch 32/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8123 - loss: 0.5099 \n",
      "Epoch 33/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8330 - loss: 0.5324 \n",
      "Epoch 34/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8123 - loss: 0.5087 \n",
      "Epoch 35/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.3078 \n",
      "Epoch 36/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8125 - loss: 0.6607 \n",
      "Epoch 37/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8473 - loss: 0.4558 \n",
      "Epoch 38/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.4768 \n",
      "Epoch 39/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8408 - loss: 0.4374 \n",
      "Epoch 40/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8102 - loss: 0.5553 \n",
      "Epoch 41/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.4804 \n",
      "Epoch 42/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8144 - loss: 0.5563 \n",
      "Epoch 43/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7772 - loss: 0.5275 \n",
      "Epoch 44/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8980 - loss: 0.3081 \n",
      "Epoch 45/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.3274 \n",
      "Epoch 46/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8244 - loss: 0.4223 \n",
      "Epoch 47/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8119 - loss: 0.4257 \n",
      "Epoch 48/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9010 - loss: 0.3967 \n",
      "Epoch 49/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8635 - loss: 0.4249\n",
      "Epoch 50/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.2340 \n",
      "Epoch 51/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.4855 \n",
      "Epoch 52/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.3786 \n",
      "Epoch 53/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.3650 \n",
      "Epoch 54/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8144 - loss: 0.5301 \n",
      "Epoch 55/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.3354 \n",
      "Epoch 56/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8351 - loss: 0.4287 \n",
      "Epoch 57/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8759 - loss: 0.3532 \n",
      "Epoch 58/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.2727 \n",
      "Epoch 59/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8440 - loss: 0.3423 \n",
      "Epoch 60/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8790 - loss: 0.3161 \n",
      "Epoch 61/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.3080 \n",
      "Epoch 62/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.3470 \n",
      "Epoch 63/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9164 - loss: 0.2616 \n",
      "Epoch 64/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8632 - loss: 0.3850 \n",
      "Epoch 65/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8754 - loss: 0.3708 \n",
      "Epoch 66/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.3709 \n",
      "Epoch 67/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8800 - loss: 0.2308 \n",
      "Epoch 68/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9045 - loss: 0.3175 \n",
      "Epoch 69/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8683 - loss: 0.3497 \n",
      "Epoch 70/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8678 - loss: 0.3412 \n",
      "Epoch 71/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8631 - loss: 0.4035 \n",
      "Epoch 72/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.2664 \n",
      "Epoch 73/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.3175 \n",
      "Epoch 74/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8312 - loss: 0.6121 \n",
      "Epoch 75/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.2461 \n",
      "Epoch 76/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2464 \n",
      "Epoch 77/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8580 - loss: 0.2990 \n",
      "Epoch 78/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8915 - loss: 0.2761 \n",
      "Epoch 79/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.3116 \n",
      "Epoch 80/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9045 - loss: 0.2629 \n",
      "Epoch 81/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8779 - loss: 0.2952 \n",
      "Epoch 82/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.2761 \n",
      "Epoch 83/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8533 - loss: 0.4116 \n",
      "Epoch 84/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8762 - loss: 0.3791 \n",
      "Epoch 85/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8526 - loss: 0.3067 \n",
      "Epoch 86/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8896 - loss: 0.3487 \n",
      "Epoch 87/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.3197 \n",
      "Epoch 88/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.1984 \n",
      "Epoch 89/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8564 - loss: 0.3881 \n",
      "Epoch 90/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8504 - loss: 0.2834 \n",
      "Epoch 91/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8936 - loss: 0.3160 \n",
      "Epoch 92/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8741 - loss: 0.3320 \n",
      "Epoch 93/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8751 - loss: 0.3474 \n",
      "Epoch 94/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8483 - loss: 0.3474 \n",
      "Epoch 95/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8715 - loss: 0.3200 \n",
      "Epoch 96/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.2021 \n",
      "Epoch 97/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9094 - loss: 0.2266  \n",
      "Epoch 98/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8493 - loss: 0.3231 \n",
      "Epoch 99/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.2012 \n",
      "Epoch 100/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8593 - loss: 0.3682 \n",
      "Epoch 101/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.1922 \n",
      "Epoch 102/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9325 - loss: 0.2608 \n",
      "Epoch 103/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9047 - loss: 0.2796 \n",
      "Epoch 104/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8574 - loss: 0.3571 \n",
      "Epoch 105/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9014 - loss: 0.2771 \n",
      "Epoch 106/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.3172 \n",
      "Epoch 107/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8779 - loss: 0.2067 \n",
      "Epoch 108/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.2534 \n",
      "Epoch 109/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.2414 \n",
      "Epoch 110/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9057 - loss: 0.1807  \n",
      "Epoch 111/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9045 - loss: 0.2332 \n",
      "Epoch 112/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.4731 \n",
      "Epoch 113/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.3009 \n",
      "Epoch 114/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.2745 \n",
      "Epoch 115/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.3626 \n",
      "Epoch 116/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.2038 \n",
      "Epoch 117/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2354 \n",
      "Epoch 118/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9421 - loss: 0.1911 \n",
      "Epoch 119/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8727 - loss: 0.3776 \n",
      "Epoch 120/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.1639 \n",
      "Epoch 121/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8712 - loss: 0.2898 \n",
      "Epoch 122/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8264 - loss: 0.2673 \n",
      "Epoch 123/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8442 - loss: 0.3250  \n",
      "Epoch 124/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8538 - loss: 0.3990 \n",
      "Epoch 125/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.3228 \n",
      "Epoch 126/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 0.2336 \n",
      "Epoch 127/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9427 - loss: 0.2256 \n",
      "Epoch 128/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8642 - loss: 0.3199 \n",
      "Epoch 129/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2161 \n",
      "Epoch 130/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8496 - loss: 0.2953 \n",
      "Epoch 131/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2661 \n",
      "Epoch 132/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8644 - loss: 0.3203 \n",
      "Epoch 133/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.4275 \n",
      "Epoch 134/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9131 - loss: 0.2992 \n",
      "Epoch 135/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.2929 \n",
      "Epoch 136/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1614 \n",
      "Epoch 137/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.3086 \n",
      "Epoch 138/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8624 - loss: 0.2875 \n",
      "Epoch 139/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9037 - loss: 0.2121 \n",
      "Epoch 140/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.2219  \n",
      "Epoch 141/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8517 - loss: 0.3260 \n",
      "Epoch 142/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2506 \n",
      "Epoch 143/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8743 - loss: 0.3383 \n",
      "Epoch 144/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9362 - loss: 0.2614 \n",
      "Epoch 145/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9001 - loss: 0.2326 \n",
      "Epoch 146/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2150 \n",
      "Epoch 147/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8483 - loss: 0.3122 \n",
      "Epoch 148/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.2992 \n",
      "Epoch 149/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.2517 \n",
      "Epoch 150/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8759 - loss: 0.2868 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e011bd6c50>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x =train_X, y= train_Y, epochs = 150, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d0350-dbf7-4085-b8c9-18cfff655364",
   "metadata": {},
   "source": [
    "8. Creating a test set to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7923df1f-91f6-4dad-a288-835b8ee7926e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'greeting',\n",
       "   'patterns': ['Hi',\n",
       "    'Hello',\n",
       "    'Hey',\n",
       "    'Good morning',\n",
       "    'Good afternoon',\n",
       "    'Hi there',\n",
       "    'Hey there',\n",
       "    'Yo'],\n",
       "   'responses': [\"Hey! How's it going?\",\n",
       "    \"Hello! What's up?\",\n",
       "    'Hi there! How can I help?',\n",
       "    \"Hi! How's your day?\",\n",
       "    \"Hello! What's new?\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'noanswer',\n",
       "   'patterns': [],\n",
       "   'responses': [\"Sorry, can't understand you\",\n",
       "    'Please give me more info',\n",
       "    'Not sure I understand'],\n",
       "   'context': ''},\n",
       "  {'tag': 'job',\n",
       "   'patterns': ['What is your job', 'What is your work'],\n",
       "   'responses': ['My job is to make you feel like everything is okay.',\n",
       "    'I work to serve you as well as possible'],\n",
       "   'context': ''},\n",
       "  {'tag': 'age',\n",
       "   'patterns': ['What is your age', 'How old are you', 'When were you born'],\n",
       "   'responses': ['I was born in 2021'],\n",
       "   'context': ''},\n",
       "  {'tag': 'feeling',\n",
       "   'patterns': ['How are you today', 'How are you'],\n",
       "   'responses': ['I am feeling good, you?',\n",
       "    'Very good and you?',\n",
       "    \"Actually, I'm okay and you?\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'good',\n",
       "   'patterns': ['I am good too',\n",
       "    'I feel fine',\n",
       "    'Good !',\n",
       "    'Fine',\n",
       "    'I am good',\n",
       "    'I am great',\n",
       "    'great'],\n",
       "   'responses': ['That is perfect!', \"So, everything's okay!\"],\n",
       "   'context': 'feeling'},\n",
       "  {'tag': 'bad',\n",
       "   'patterns': ['I am feeling bad', 'No I am sad', 'No'],\n",
       "   'responses': ['I hope you will feel better !'],\n",
       "   'context': 'feeling'},\n",
       "  {'tag': 'actions',\n",
       "   'patterns': ['What can you do', 'What can I ask you', 'Can you help me'],\n",
       "   'responses': ['I can do a lot of things but here are some of my skills, you can ask me: the capital of a country, its currency and its area. A random number. To calculate a math operation.'],\n",
       "   'context': ''},\n",
       "  {'tag': 'women',\n",
       "   'patterns': ['Are you a girl', 'You are a women'],\n",
       "   'responses': ['Sure, I am a women'],\n",
       "   'context': ''},\n",
       "  {'tag': 'men',\n",
       "   'patterns': ['Are you a men', 'Are you a boy'],\n",
       "   'responses': ['No, I am a women'],\n",
       "   'context': ''},\n",
       "  {'tag': 'thanks',\n",
       "   'patterns': ['Thank you',\n",
       "    'Thank you very much',\n",
       "    'thanks',\n",
       "    'Thank you',\n",
       "    'Thanks a lot',\n",
       "    'Thanks',\n",
       "    'Much appreciated',\n",
       "    \"You're the best\"],\n",
       "   'responses': ['I only do my job️',\n",
       "    'No problem!',\n",
       "    'No worries!',\n",
       "    'Happy to help!',\n",
       "    'Anytime!',\n",
       "    \"You're welcome!\",\n",
       "    'Glad I could help!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'goodbye',\n",
       "   'patterns': ['Goodbye',\n",
       "    'Good afternoon',\n",
       "    'Bye',\n",
       "    'Goodbye',\n",
       "    'Bye',\n",
       "    'See you later',\n",
       "    'Take care',\n",
       "    'Catch you later',\n",
       "    'Peace out'],\n",
       "   'responses': ['Goodbye!',\n",
       "    'See you soon!',\n",
       "    'Bye! Have an awesome day!',\n",
       "    'See you later, alligator!',\n",
       "    'Take care! Talk soon.',\n",
       "    'Catch you later!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'city',\n",
       "   'patterns': ['Where do you live'],\n",
       "   'responses': ['I live in a server located in the US!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'action',\n",
       "   'patterns': ['What are you doing'],\n",
       "   'responses': [\"Actually, I'm chatting with somebody\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'wait',\n",
       "   'patterns': ['Can you wait 2 minutes', 'Please wait', 'Wait 2 secs please'],\n",
       "   'responses': ['Sure! I wait.'],\n",
       "   'context': ''},\n",
       "  {'tag': 'still_there',\n",
       "   'patterns': ['Are you still there?', 'Are you here?'],\n",
       "   'responses': ['Of course! Always at your service.'],\n",
       "   'context': ''},\n",
       "  {'tag': 'personal_info',\n",
       "   'patterns': ['How old are you?',\n",
       "    \"What's your age?\",\n",
       "    'When were you created?',\n",
       "    \"What's your name?\",\n",
       "    'Do you have a name?',\n",
       "    'Who are you?'],\n",
       "   'responses': [\"I'm ChatBot, your friendly virtual assistant!\",\n",
       "    \"I don't have an age, but I'm here to help you!\",\n",
       "    'You can call me ChatBot!',\n",
       "    \"I'm ChatBot, nice to meet you!\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'weather',\n",
       "   'patterns': [\"What's the weather like today?\",\n",
       "    'Tell me about the weather',\n",
       "    'Is it going to rain?',\n",
       "    \"How's the weather?\"],\n",
       "   'responses': [\"I can't check the weather, but you can try a weather app!\",\n",
       "    'Not sure, but you can check online!',\n",
       "    'Weather is always a surprise!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'help',\n",
       "   'patterns': ['Can you help me?',\n",
       "    'I need assistance',\n",
       "    'Help me with something',\n",
       "    'What can you do?',\n",
       "    'What are your features?',\n",
       "    'Tell me about your capabilities'],\n",
       "   'responses': [\"I'm here to chat and help with whatever you need!\",\n",
       "    'I can answer questions, tell jokes, and more. Just ask!',\n",
       "    \"What do you need help with? I'm here for you!\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'jokes',\n",
       "   'patterns': ['Tell me a joke',\n",
       "    'Can you make me laugh?',\n",
       "    'Share a funny story',\n",
       "    'Got any jokes?'],\n",
       "   'responses': [\"Why don't scientists trust atoms? Because they make up everything!\",\n",
       "    'Why did the scarecrow win an award? Because he was outstanding in his field!',\n",
       "    \"Want to hear a construction joke? Oh, never mind, I'm still working on it.\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'small_talk',\n",
       "   'patterns': ['How are you?',\n",
       "    \"How's it going?\",\n",
       "    \"What's up?\",\n",
       "    \"How's your day?\",\n",
       "    'How are things?',\n",
       "    \"How's life?\",\n",
       "    \"How's everything?\"],\n",
       "   'responses': [\"I'm doing great! How about you?\",\n",
       "    'All good here! What about you?',\n",
       "    \"Just chilling! How's your day going?\",\n",
       "    \"Life's good! How's everything with you?\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'compliment',\n",
       "   'patterns': [\"You're awesome\",\n",
       "    \"You're the best\",\n",
       "    'I like you',\n",
       "    \"You're cool\",\n",
       "    'Thanks for being awesome'],\n",
       "   'responses': [\"You're too kind!\",\n",
       "    \"Thanks! You're awesome too!\",\n",
       "    'I like you too!',\n",
       "    'You rock!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'movie_recommendation',\n",
       "   'patterns': ['Recommend a movie',\n",
       "    \"What's a good movie to watch?\",\n",
       "    'Any movie suggestions?',\n",
       "    'What should I watch?'],\n",
       "   'responses': ['Depends on what you like! Have you seen any good comedies lately?',\n",
       "    \"How about a classic? You can't go wrong with something like 'The Shawshank Redemption'!\",\n",
       "    \"In the mood for action? 'Mad Max: Fury Road' is a wild ride!\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'music_recommendation',\n",
       "   'patterns': ['Recommend some music',\n",
       "    \"What's a good song to listen to?\",\n",
       "    'Any music suggestions?',\n",
       "    'What should I listen to?'],\n",
       "   'responses': [\"What genre do you like? I'm a fan of all kinds!\",\n",
       "    'How about some chill vibes with lo-fi beats?',\n",
       "    'In the mood for something upbeat? Try some pop hits!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'book_recommendation',\n",
       "   'patterns': ['Recommend a book',\n",
       "    \"What's a good book to read?\",\n",
       "    'Any book suggestions?',\n",
       "    'What should I read?'],\n",
       "   'responses': [\"If you like thrillers, 'Gone Girl' is a great choice!\",\n",
       "    \"For some fantasy, you can't go wrong with 'Harry Potter'!\",\n",
       "    \"In the mood for non-fiction? 'Sapiens' is really interesting!\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'sports_news',\n",
       "   'patterns': ['Tell me about sports news',\n",
       "    \"What's happening in the sports world?\",\n",
       "    'Any sports updates?',\n",
       "    \"What's new in sports?\"],\n",
       "   'responses': [\"There's always something happening in sports! Check out the latest news online.\",\n",
       "    'You can get the latest updates on sports news websites.',\n",
       "    \"I'm not a sports expert, but I can help you find the news!\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'tech_news',\n",
       "   'patterns': [\"What's new in technology?\",\n",
       "    'Tell me about tech trends',\n",
       "    'Any tech updates?',\n",
       "    \"What's happening in tech?\"],\n",
       "   'responses': ['Tech is always evolving! Have you checked out the latest gadgets?',\n",
       "    'You can stay updated with tech blogs and news sites.',\n",
       "    'So many cool innovations happening! What are you interested in?'],\n",
       "   'context': ''},\n",
       "  {'tag': 'coding_help',\n",
       "   'patterns': ['Can you help me with coding?',\n",
       "    'I need coding assistance',\n",
       "    'Programming help',\n",
       "    'How do I code this?'],\n",
       "   'responses': ['Sure, I can help with coding! What language are you using?',\n",
       "    \"Need help with a specific coding problem? I'm here for you!\",\n",
       "    \"Let's tackle that coding challenge together!\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'hobbies',\n",
       "   'patterns': ['What do you like to do for fun?',\n",
       "    'Any hobbies?',\n",
       "    'What are your interests?',\n",
       "    'Do you have any hobbies?'],\n",
       "   'responses': ['I love chatting with you and learning new things!',\n",
       "    'My hobby is helping people out with their questions.',\n",
       "    'I enjoy making people smile with my jokes and stories!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'favorite_color',\n",
       "   'patterns': [\"What's your favorite color?\"],\n",
       "   'responses': ['I love all colors equally!'],\n",
       "   'context': ''},\n",
       "  {'tag': 'like_pizza',\n",
       "   'patterns': ['Do you like pizza?'],\n",
       "   'responses': [\"Pizza is awesome! What's your favorite topping?\"],\n",
       "   'context': ''},\n",
       "  {'tag': 'favorite_movie',\n",
       "   'patterns': ['Do you have a favorite movie?'],\n",
       "   'responses': [\"I don't watch movies, but I've heard 'Inception' is a mind-bender!\"],\n",
       "   'context': ''}]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file2 = open(\"intentstest.json\", encoding=\"utf-8\").read()\n",
    "data_test = json.loads(data_file)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "313d3cd3-3041-4e00-b00a-fd62470b19b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test[\"intents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3215546b-b891-4c52-98d4-25f717954d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "words_test, tag_classes_test, predictor_patterns_test, target_tags_test = initialize_lists(data_test)\n",
    "\n",
    "test = []\n",
    "out2 = [0]*len(tag_classes)\n",
    "for idx, pattern in enumerate(predictor_patterns_test):\n",
    "    pattern_lemma = lemmatizer.lemmatize(pattern.lower())\n",
    "    #pattern_lemma = pattern_lemmatizer(pattern)\n",
    "    bow2 = bag_of_words(pattern_lemma, vocab)\n",
    "    output2 = list(out2)\n",
    "    output2[tag_classes.index(target_tags_test[idx])] = 1\n",
    "    test.append([bow2, output2])\n",
    "\n",
    "random_test = test\n",
    "random.shuffle(random_test)\n",
    "test_array = np.array(random_test, dtype=object)\n",
    "test_X = np.array(list(test_array[:,0]))\n",
    "test_Y = np.array(list(test_array[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "807097df-55b6-44c4-a877-763c1a4fae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9358 - loss: 0.0916  \n",
      "Test accuracy: 0.9411764740943909\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_X, test_Y)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310e1b76-ecee-4326-b601-12da0bbec420",
   "metadata": {},
   "source": [
    "8. Following functions are made to chat with humans. Predict class predicts the tag class for a given text. Get responce function choose a random response according to predictet tag using our json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80c35ce3-deb5-4618-ac3d-e5af547a618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_tag_class(text, vocab, tag_classes):\n",
    "    bow = bag_of_words(text, vocab)\n",
    "    bow = bow.reshape(1, -1)\n",
    "    \n",
    "    predictions = model.predict(bow, verbose=0)[0]\n",
    "    \n",
    "    most_probabble =  [[idx,pred] for idx,pred in enumerate(predictions) if pred > 0.5]\n",
    "    most_probabble.sort(key=lambda X: X[1], reverse=True)\n",
    "    \n",
    "    pred_tag_classes =[]\n",
    "    for tags in most_probabble:\n",
    "        pred_tag_classes.append(tag_classes[tags[0]])\n",
    "    return pred_tag_classes\n",
    "\n",
    "def get_responces(predicted_classes, intents):\n",
    "    if len(predicted_classes) == 0:\n",
    "        result = \"Sorry, I cant't understand what you are telling\"\n",
    "    else:\n",
    "        tag = predicted_classes[0]\n",
    "        list_of_intents = intents[\"intents\"]\n",
    "        for intent in list_of_intents:\n",
    "            if intent[\"tag\"] == tag:\n",
    "                result = random.choice(intent[\"responses\"])\n",
    "                break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd2cc257-d23b-40ea-a070-5836acc2e98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 0 to stop the chat\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You :  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot : Hello! What's up?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You :  how are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot : I'm doing great! How about you?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You :  im fine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot : That is perfect!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You :  who are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot : I'm ChatBot, your friendly virtual assistant!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You :  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot : See you later, alligator!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter 0 to stop the chat\")\n",
    "print(\"\\n\")\n",
    "while True:\n",
    "    text = input(\"You : \")\n",
    "    if text == \"0\":\n",
    "        break\n",
    "    pattern = pattern_lemmatizer(text)\n",
    "    result = get_responces(predict_tag_class(pattern,vocab, tag_classes), data)\n",
    "    print(\"ChatBot :\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca23c4d-d18f-4f77-be9d-2ab3f76a3e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
